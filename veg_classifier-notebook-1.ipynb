{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CtrGHzK2zMdIoC-y-fO20cSemgDrEhcv",
      "authorship_tag": "ABX9TyNnEOrJ5z3oLEAGodiJ0Ea8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kokochka/veggies-classifier/blob/main/veg_classifier-notebook-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FrQNUnTJCOzA",
        "outputId": "f0a5b6b7-c11f-4d80-a684-cabd359a3595",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# @title Installing frameworks\n",
        "!pip install tensorflow keras kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Находим kaggle.json\n",
        "import os\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "XmhF86g5Cokc",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Скачиваем папку с датасетом\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Авторизация в Kaggle\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Скачивание датасета\n",
        "dataset_path = 'vegetable-image-dataset'\n",
        "api.dataset_download_files('misrakahmed/vegetable-image-dataset', path=dataset_path, unzip=True)\n"
      ],
      "metadata": {
        "id": "ALCeew4bSXnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3123bcfd-c3be-4aed-b12b-117a6cf7d870"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Препроцессинг изображений + генератор данных\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Путь к директории с изображениями\n",
        "base_dir = '/content/vegetable-image-dataset/Vegetable Images'\n",
        "\n",
        "# Размеры изображений\n",
        "img_height, img_width = 150, 150\n",
        "\n",
        "# Подготовка генераторов данных\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/vegetable-image-dataset/Vegetable Images/train',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/vegetable-image-dataset/Vegetable Images/validation',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "     '/content/vegetable-image-dataset/Vegetable Images/test',\n",
        "     target_size=(img_height, img_width),\n",
        "     batch_size=32,\n",
        "     class_mode='categorical'\n",
        " )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ2iM0SmTqvI",
        "outputId": "a37a72c1-600d-49f9-ecae-ac5341ba758b",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12000 images belonging to 15 classes.\n",
            "Found 600 images belonging to 15 classes.\n",
            "Found 3000 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основные изменения:\n",
        "\n",
        "Добавлены слои BatchNormalization после каждого сверточного слоя для нормализации выходов и ускорения обучения.\n",
        "Включены дополнительные слои Dropout для предотвращения переобучения.\n",
        "Добавлен еще один сверточный слой для более глубокого представления признаков.\n",
        "В конце добавлен дополнительный полносвязный слой с BatchNormalization и Dropout для лучшего обобщения.\n",
        "Такая архитектура должна помочь улучшить качество классификации, особенно при большом количестве данных.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "54mSUzqIgDIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Построение нейросети\n",
        "\n",
        "здесь два варианта: нижний - тот на котором уже есть готовая модель, обученная 30 раз;\n",
        "верхняя - доработана 28.05"
      ],
      "metadata": {
        "id": "_ZK2mid_TnZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Измененная и усложненная структура нейросети\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(15, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "IuoQ64BLgElu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Первый вариант нейросети - на нем натренирована модель\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(15, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "rtLi-2GpUKO1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тренирование модели\n",
        "\n",
        "Было задано 30 эпох и сохранение модели после каждой эпохи"
      ],
      "metadata": {
        "id": "5N39cmz1T8gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Вызываем сохранение модели в тренировке после каждой эпохи\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    'vegetable_classifier_epoch_{epoch:02d}_val_acc_{val_accuracy:.2f}.h5',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    save_freq='epoch'\n",
        ")\n"
      ],
      "metadata": {
        "id": "8d0sogN-74IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Тренируем модель, задано 35 эпох\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=35,\n",
        "    callbacks=[checkpoint_cb]  # викликаємо збереження моделі після кожної епохи\n",
        ")\n",
        "\n",
        "# оцінка моделі протягом навчання\n",
        "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nokhpKrhUO_B",
        "outputId": "e0c66ad3-c05b-4cf0-a84d-b107838bd1ac",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "375/375 [==============================] - ETA: 0s - loss: 1.2898 - accuracy: 0.5777"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 710s 2s/step - loss: 1.2898 - accuracy: 0.5777 - val_loss: 0.5768 - val_accuracy: 0.8125\n",
            "Epoch 2/35\n",
            "375/375 [==============================] - 700s 2s/step - loss: 0.5529 - accuracy: 0.8221 - val_loss: 0.3108 - val_accuracy: 0.9149\n",
            "Epoch 3/35\n",
            "375/375 [==============================] - 704s 2s/step - loss: 0.3381 - accuracy: 0.8891 - val_loss: 0.2607 - val_accuracy: 0.9062\n",
            "Epoch 4/35\n",
            "375/375 [==============================] - 703s 2s/step - loss: 0.2087 - accuracy: 0.9338 - val_loss: 0.1946 - val_accuracy: 0.9514\n",
            "Epoch 5/35\n",
            "375/375 [==============================] - 711s 2s/step - loss: 0.1625 - accuracy: 0.9487 - val_loss: 0.1677 - val_accuracy: 0.9531\n",
            "Epoch 6/35\n",
            "375/375 [==============================] - 693s 2s/step - loss: 0.1250 - accuracy: 0.9615 - val_loss: 0.1449 - val_accuracy: 0.9601\n",
            "Epoch 7/35\n",
            "375/375 [==============================] - 699s 2s/step - loss: 0.1056 - accuracy: 0.9689 - val_loss: 0.2683 - val_accuracy: 0.9288\n",
            "Epoch 8/35\n",
            "375/375 [==============================] - 699s 2s/step - loss: 0.0921 - accuracy: 0.9722 - val_loss: 0.1266 - val_accuracy: 0.9740\n",
            "Epoch 9/35\n",
            "375/375 [==============================] - 702s 2s/step - loss: 0.0968 - accuracy: 0.9689 - val_loss: 0.1680 - val_accuracy: 0.9635\n",
            "Epoch 10/35\n",
            "375/375 [==============================] - 699s 2s/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.1199 - val_accuracy: 0.9670\n",
            "Epoch 11/35\n",
            "375/375 [==============================] - 686s 2s/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.1865 - val_accuracy: 0.9566\n",
            "Epoch 12/35\n",
            "375/375 [==============================] - 688s 2s/step - loss: 0.0583 - accuracy: 0.9814 - val_loss: 0.1946 - val_accuracy: 0.9531\n",
            "Epoch 13/35\n",
            "375/375 [==============================] - 711s 2s/step - loss: 0.0661 - accuracy: 0.9779 - val_loss: 0.1826 - val_accuracy: 0.9618\n",
            "Epoch 14/35\n",
            "375/375 [==============================] - 707s 2s/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 0.1544 - val_accuracy: 0.9653\n",
            "Epoch 15/35\n",
            "375/375 [==============================] - 696s 2s/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.1641 - val_accuracy: 0.9722\n",
            "Epoch 16/35\n",
            "375/375 [==============================] - 695s 2s/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.1189 - val_accuracy: 0.9635\n",
            "Epoch 17/35\n",
            "375/375 [==============================] - 705s 2s/step - loss: 0.0549 - accuracy: 0.9839 - val_loss: 0.1898 - val_accuracy: 0.9635\n",
            "Epoch 18/35\n",
            "375/375 [==============================] - 700s 2s/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.1262 - val_accuracy: 0.9670\n",
            "Epoch 19/35\n",
            "375/375 [==============================] - 703s 2s/step - loss: 0.0436 - accuracy: 0.9859 - val_loss: 0.1432 - val_accuracy: 0.9740\n",
            "Epoch 20/35\n",
            "375/375 [==============================] - 694s 2s/step - loss: 0.0483 - accuracy: 0.9851 - val_loss: 0.2093 - val_accuracy: 0.9566\n",
            "Epoch 21/35\n",
            "375/375 [==============================] - 720s 2s/step - loss: 0.0539 - accuracy: 0.9833 - val_loss: 0.1553 - val_accuracy: 0.9601\n",
            "Epoch 22/35\n",
            "375/375 [==============================] - 714s 2s/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.1619 - val_accuracy: 0.9618\n",
            "Epoch 23/35\n",
            "375/375 [==============================] - 693s 2s/step - loss: 0.0540 - accuracy: 0.9849 - val_loss: 0.1274 - val_accuracy: 0.9688\n",
            "Epoch 24/35\n",
            "375/375 [==============================] - 706s 2s/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.1791 - val_accuracy: 0.9601\n",
            "Epoch 25/35\n",
            "375/375 [==============================] - 710s 2s/step - loss: 0.0429 - accuracy: 0.9882 - val_loss: 0.1955 - val_accuracy: 0.9618\n",
            "Epoch 26/35\n",
            "375/375 [==============================] - 1122s 3s/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.2396 - val_accuracy: 0.9618\n",
            "Epoch 27/35\n",
            "375/375 [==============================] - 750s 2s/step - loss: 0.0521 - accuracy: 0.9852 - val_loss: 0.2473 - val_accuracy: 0.9601\n",
            "Epoch 28/35\n",
            "375/375 [==============================] - 689s 2s/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.1871 - val_accuracy: 0.9705\n",
            "Epoch 29/35\n",
            "375/375 [==============================] - 704s 2s/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.1773 - val_accuracy: 0.9653\n",
            "Epoch 30/35\n",
            "375/375 [==============================] - 691s 2s/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.0876 - val_accuracy: 0.9826\n",
            "Epoch 31/35\n",
            "375/375 [==============================] - 688s 2s/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.2018 - val_accuracy: 0.9635\n",
            "Epoch 32/35\n",
            "375/375 [==============================] - 696s 2s/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.1631 - val_accuracy: 0.9688\n",
            "Epoch 33/35\n",
            "375/375 [==============================] - 700s 2s/step - loss: 0.0404 - accuracy: 0.9900 - val_loss: 0.1875 - val_accuracy: 0.9653\n",
            "Epoch 34/35\n",
            "188/375 [==============>...............] - ETA: 5:42 - loss: 0.0312 - accuracy: 0.9920"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Сохраняем готовую модель если успешно прошло 35 эпох\n",
        "\n",
        "model.save('vegetable_classifier_model.h5')\n"
      ],
      "metadata": {
        "id": "Sd1xJMQXXuxk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Тестирование полученной модели на предзагруженой картинке\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    class_labels = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "    return class_labels[predicted_class[0]]\n",
        "\n",
        "# Пример использования\n",
        "img_path = '/content/cucumber.jpeg'  # Замените на путь к вашему изображению\n",
        "print(predict_image(img_path))\n"
      ],
      "metadata": {
        "id": "LxDnhAq0XLb5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}